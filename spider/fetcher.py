import os
import json
import requests
import mimetypes
from datetime import datetime
from bs4 import BeautifulSoup
from urllib.parse import urljoin
import urllib3

# ç¦ç”¨ SSL è­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# è‡ªåŠ¨å®šä½ cookie æ–‡ä»¶
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
COOKIE_FILE = os.path.join(BASE_DIR, "data", "cookies.json")
TEMP_DIR = os.path.join(BASE_DIR, "data", "temp_files")

DEFAULT_HEADERS = {
    # å¿…é¡»ä¸ LoginManager ä¿æŒä¸€è‡´ï¼Œå¦åˆ™ä¼šè¢«è¸¢ä¸‹çº¿
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
}

def get_requests_cookies():
    """å·¥å…·å‡½æ•°ï¼šåŠ è½½ Cookie"""
    cookie_dict = {}
    if os.path.exists(COOKIE_FILE):
        try:
            with open(COOKIE_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
                for item in data:
                    cookie_dict[item['name']] = item['value']
        except:
            pass
    return cookie_dict

def download_file(url, session):
    """å·¥å…·å‡½æ•°ï¼šä¸‹è½½æ–‡ä»¶"""
    if not os.path.exists(TEMP_DIR):
        os.makedirs(TEMP_DIR)

    try:
        print(f"    â¬‡ï¸ ä¸‹è½½é™„ä»¶: {url.split('/')[-1][:20]}...")
        res = session.get(url, stream=True, verify=False, timeout=30)

        # æ™ºèƒ½çŒœæµ‹åç¼€
        content_type = res.headers.get('Content-Type', '').split(';')[0]
        ext = mimetypes.guess_extension(content_type) or ".dat"

        # å¦‚æœ URL æœ¬èº«æœ‰åç¼€ï¼Œä¼˜å…ˆç”¨ URL çš„
        if '.' in url.split('/')[-1]:
            ext = '.' + url.split('/')[-1].split('.')[-1]

        filename = f"attach_{datetime.now().strftime('%H%M%S_%f')}{ext}"
        path = os.path.join(TEMP_DIR, filename)

        with open(path, "wb") as f:
            for chunk in res.iter_content(chunk_size=8192):
                f.write(chunk)
        return path
    except Exception as e:
        print(f"    âš ï¸ ä¸‹è½½å¤±è´¥: {e}")
        return None

# ==========================================
# ğŸ”§ åŸå­ç»„ä»¶ï¼šè§£æé€»è¾‘ (æ‹†åˆ†é™ä½å¤æ‚åº¦)
# ==========================================

def _setup_session():
    """åŸå­ä»»åŠ¡ï¼šåˆå§‹åŒ–ä¼šè¯"""
    session = requests.Session()
    session.headers.update(DEFAULT_HEADERS)
    session.cookies.update(get_requests_cookies())
    return session

def _extract_attachments(soup, base_url, session):
    """åŸå­ä»»åŠ¡ï¼šä» HTML ä¸­æå–å¹¶ä¸‹è½½é™„ä»¶"""
    files = []
    # æŸ¥æ‰¾æ‰€æœ‰å¸¦ href çš„é“¾æ¥
    for a in soup.find_all('a', href=True):
        href = a['href']
        full_link = urljoin(base_url, href)
        lower_link = full_link.lower()

        # é™„ä»¶åç¼€ç™½åå•
        valid_exts = ['.pdf', '.doc', '.docx', '.xls', '.xlsx', '.ppt', '.pptx', '.zip', '.rar']

        if any(x in lower_link for x in valid_exts):
            # è¿‡æ»¤åƒåœ¾é“¾æ¥
            if 'mailto:' in lower_link or 'javascript:' in lower_link:
                continue

            f_path = download_file(full_link, session)
            if f_path:
                files.append(f_path)
    return files

def _process_html_response(response, session, url):
    """åŸå­ä»»åŠ¡ï¼šå¤„ç† HTML ç±»å‹çš„å“åº”"""
    soup = BeautifulSoup(response.text, 'html.parser')

    # 1. æå–æ­£æ–‡ (ç®€å•æ¸…æ´—)
    text = soup.get_text(separator='\n', strip=True)

    # 2. æå–é™„ä»¶
    files = _extract_attachments(soup, url, session)

    return {
        "type": "compound",
        "text": text[:5000], # ç¨å¾®ç»™å¤šç‚¹ä¸Šä¸‹æ–‡
        "files": files
    }

# ==========================================
# ğŸš€ ä¸»å…¥å£
# ==========================================

def fetch_content(url):
    """
    ä¸»æŠ“å–å‡½æ•°
    ç°åœ¨å®ƒåªæ˜¯ä¸€ä¸ªè°ƒåº¦å‘˜ï¼Œå¤æ‚åº¦æä½
    """
    session = _setup_session()

    try:
        response = session.get(url, verify=False, timeout=15)
        response.encoding = 'utf-8' # å¼ºåˆ¶ UTF-8ï¼Œé˜²æ­¢ä¹±ç 

        content_type = response.headers.get('Content-Type', '')

        # åˆ†æµå¤„ç†
        if 'text/html' in content_type:
            return _process_html_response(response, session, url)
        else:
            # å¦‚æœç›´æ¥æ˜¯æ–‡ä»¶é“¾æ¥
            path = download_file(url, session)
            return {"type": "file", "path": path}

    except Exception as e:
        print(f"    âŒ æŠ“å–å†…å®¹å‡ºé”™: {e}")
        return None