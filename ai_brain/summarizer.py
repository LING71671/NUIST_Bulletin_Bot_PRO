import os
import base64
import fitz  # PyMuPDF
import docx
import pandas as pd
from pptx import Presentation
from openai import OpenAI
import sys
import logging

# å¼•ç”¨æ ¹ç›®å½•é…ç½®
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import config

# åˆå§‹åŒ–æ¨¡å—çº§æ—¥å¿—
logger = logging.getLogger(__name__)

KEYS = config.AI_KEYS
CLIENTS = {}
try:
    if KEYS["zhipu"]:
        CLIENTS["zhipu"] = OpenAI(api_key=KEYS["zhipu"], base_url="https://open.bigmodel.cn/api/paas/v4/")
    if KEYS["aliyun"]:
        CLIENTS["aliyun"] = OpenAI(api_key=KEYS["aliyun"], base_url="https://dashscope.aliyuncs.com/compatible-mode/v1")
    if KEYS["deepseek"]:
        CLIENTS["deepseek"] = OpenAI(api_key=KEYS["deepseek"], base_url="https://api.deepseek.com")
    if KEYS["silicon"]:
        CLIENTS["silicon"] = OpenAI(api_key=KEYS["silicon"], base_url="https://api.siliconflow.cn/v1")
except Exception as e:
    logger.warning(f"âš ï¸ API Client åˆå§‹åŒ–è­¦å‘Š: {e}")

MODELS = {
    "commander": ("deepseek", "deepseek-chat"),   # ä¸»åŠ›æ€»ç»“
    "strategist": ("aliyun", "qwen-max"),         # å¤‡ç”¨æ€»ç»“
    "hunter": ("zhipu", "glm-4-flash"),           # å¿«é€Ÿè¿‡æ»¤ (å…è´¹/ä¾¿å®œ)
    "vision": ("zhipu", "glm-4v-flash")           # è§†è§‰è¯†åˆ«
}

class BulletinSummarizer:
    def __init__(self):
        self.clients = CLIENTS
        self.models = MODELS

    def _call_ai(self, role, system_prompt, user_content):
        """é€šç”¨ AI è°ƒç”¨å‡½æ•°"""
        provider_name, model_name = self.models.get(role, ("deepseek", "deepseek-chat"))
        client = self.clients.get(provider_name)

        if not client:
            logger.warning(f"    âš ï¸ æœªé…ç½® {provider_name} çš„ API Keyï¼Œè·³è¿‡ {role}")
            return None

        try:
            temp = config.AI_CONFIG.get("TEMPERATURE", 0.1)
            timeout = config.AI_CONFIG.get("TIMEOUT", 45)
            
            response = client.chat.completions.create(
                model=model_name,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_content}
                ],
                temperature=temp,
                timeout=timeout
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.warning(f"    âš ï¸ {role} [{model_name}] è°ƒç”¨å¤±è´¥: {e}")
            return None

    # ==========================
    # ğŸ“‚ é™„ä»¶è§£ææ¨¡å—
    # ==========================

    def _extract_pdf(self, filepath):
        text = ""
        try:
            max_pages = config.AI_CONFIG.get("MAX_ATTACH_PAGES", 10)
            with fitz.open(filepath) as doc:
                for page in doc[:max_pages]:
                    text += page.get_text()
            return text[:5000]
        except: return "[PDFè§£æé”™è¯¯]"

    def _extract_word(self, filepath):
        text = ""
        try:
            doc = docx.Document(filepath)
            for para in doc.paragraphs: text += para.text + "\n"
            return text[:5000]
        except: return "[Wordè§£æé”™è¯¯]"

    def _extract_excel(self, filepath):
        try:
            df = pd.read_excel(filepath, nrows=100).fillna("")
            if df.empty: return "[ç©ºExcelè¡¨æ ¼]"
            return df.to_markdown(index=False)[:4000]
        except Exception as e:
            return f"[Excelè§£æé”™è¯¯: {str(e)}]"

    def _extract_ppt(self, filepath):
        text = ""
        try:
            max_slides = config.AI_CONFIG.get("MAX_ATTACH_SLIDES", 15)
            prs = Presentation(filepath)
            for slide in prs.slides[:max_slides]:
                for shape in slide.shapes:
                    if hasattr(shape, "text"):
                        text += shape.text + "\n"
            return text[:4000]
        except Exception as e:
            return f"[PPTè§£æé”™è¯¯: {str(e)}]"

    def _extract_image_content(self, filepath):
        logger.info(f"    ğŸ‘ï¸ æ­£åœ¨è¯†åˆ«å›¾ç‰‡å†…å®¹: {os.path.basename(filepath)}...")
        try:
            with open(filepath, "rb") as image_file:
                encoded_string = base64.b64encode(image_file.read()).decode('utf-8')

            client = self.clients.get("zhipu")
            if not client: return "[æœªé…ç½®Visionæ¨¡å‹]"

            timeout = config.AI_CONFIG.get("VISION_TIMEOUT", 30)
            response = client.chat.completions.create(
                model="glm-4v-flash",
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": "æå–å›¾ç‰‡ä¸­çš„æ‰€æœ‰æ–‡å­—ï¼Œä¿æŒåŸæœ‰æ’ç‰ˆç»“æ„ã€‚"},
                            {"type": "image_url", "image_url": {"url": encoded_string}}
                        ]
                    }
                ],
                timeout=timeout
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.warning(f"    âš ï¸ å›¾ç‰‡è¯†åˆ«å¤±è´¥: {e}")
            return "[å›¾ç‰‡æ— æ³•è¯†åˆ«]"

    # ==========================
    # ğŸ“‰ å¤æ‚åº¦ä¼˜åŒ–ï¼šåŸå­åŒ–å¤„ç†
    # ==========================

    def _get_extractor_map(self):
        """è·å–åç¼€æ˜ å°„è¡¨"""
        return {
            '.pdf': self._extract_pdf,
            '.docx': self._extract_word,
            '.doc': self._extract_word,
            '.xlsx': self._extract_excel,
            '.xls': self._extract_excel,
            '.pptx': self._extract_ppt,
            '.ppt': self._extract_ppt,
            '.jpg': self._extract_image_content,
            '.jpeg': self._extract_image_content,
            '.png': self._extract_image_content
        }

    def _process_single_file(self, path, extractors):
        """åŸå­ä»»åŠ¡ï¼šå¤„ç†å•ä¸ªæ–‡ä»¶"""
        if not os.path.exists(path):
            return None

        ext = os.path.splitext(path)[1].lower()
        handler = extractors.get(ext)

        if not handler:
            return None

        content = handler(path)
        if not content:
            return None

        return f"\n\n--- é™„ä»¶ ({os.path.basename(path)}) ---\n{content}\n"

    def process_attachments(self, file_paths):
        """å¤„ç†é™„ä»¶åˆ—è¡¨ï¼ˆçº¯éå†é€»è¾‘ï¼Œå¤æ‚åº¦æä½ï¼‰"""
        if not file_paths: return ""

        logger.info(f"    ğŸ“ æ­£åœ¨é¢„å¤„ç† {len(file_paths)} ä¸ªé™„ä»¶...")
        extractors = self._get_extractor_map()
        combined_text = ""

        for path in file_paths:
            # è°ƒç”¨åŸå­å‡½æ•°å¤„ç†å•ä¸ªæ–‡ä»¶
            result = self._process_single_file(path, extractors)
            if result:
                combined_text += result

        return combined_text

    # ==========================
    # ğŸ§± åŸå­ç»„ä»¶ï¼šä¸šåŠ¡é€»è¾‘æ‹†åˆ† (é™ç»´æ‰“å‡»å¤æ‚åº¦)
    # ==========================

    def _build_full_context(self, fetch_result, title):
        """åŸå­ä»»åŠ¡ï¼šç»„è£…æ­£æ–‡å’Œé™„ä»¶"""
        web_text = fetch_result.get('text', '')
        files = fetch_result.get('files', [])

        # è§£æé™„ä»¶
        attach_text = self.process_attachments(files)

        # ç¡®å®šæ ‡é¢˜
        safe_title = title if title else (web_text.split('\n')[0] if web_text else "æ— æ ‡é¢˜")

        # ç»„è£…å…¨æ–‡
        full_context = f"ã€å…¬å‘Šæ ‡é¢˜ã€‘: {safe_title}\n\nã€ç½‘é¡µæ­£æ–‡ã€‘:\n{web_text}\n{attach_text}"
        return safe_title, full_context

    def _check_relevance(self, safe_title, full_context):
        """åŸå­ä»»åŠ¡ï¼šHunter è¿‡æ»¤é€»è¾‘"""
        # 1. é•¿åº¦åˆç­›
        if len(full_context) < 20:
            return False

        # 2. ç™½åå•æ£€æŸ¥
        important_keywords = ["é€šçŸ¥", "å…¬å‘Š", "å…¬ç¤º", "åå•", "æ—¥ç¨‹", "å®‰æ’", "æ‹›æ ‡", "ä¸­æ ‡", "ç«èµ›", "è®²åº§", "å¤§åˆ›", "è¡¥è€ƒ", "ç”³æŠ¥"]
        if any(k in safe_title for k in important_keywords):
            logger.info(f"    ğŸ›¡ï¸ è§¦å‘ç™½åå•ï¼Œè·³è¿‡è¿‡æ»¤: {safe_title}")
            return True

        # 3. AI æ™ºèƒ½åˆ¤æ–­
        filter_prompt = """
        ä½ æ˜¯ä¸€ä¸ªå­¦æ ¡é€šçŸ¥å®¡æ ¸å‘˜ã€‚è¯·åˆ¤æ–­ä»¥ä¸‹ç½‘é¡µå†…å®¹æ˜¯å¦åŒ…å«ã€å®è´¨æ€§çš„é€šçŸ¥ã€æ–°é—»ã€æ´»åŠ¨æˆ–å…¬ç¤ºä¿¡æ¯ã€‘ã€‚
        
        ğŸ”´ åˆ¤å®šä¸º NO (æ— ä»·å€¼) çš„æƒ…å†µï¼š
        1. ä»…åŒ…å«ç½‘ç«™å¯¼èˆªèœå•ã€é¡µè„šã€ç‰ˆæƒå£°æ˜ã€å‹æƒ…é“¾æ¥ã€‚
        2. é¡µé¢æç¤ºâ€œ404â€ã€â€œæ— è®¿é—®æƒé™â€ã€â€œç³»ç»Ÿç»´æŠ¤â€ã€â€œæµ‹è¯•é¡µé¢â€ã€‚
        3. æ­£æ–‡å‡ ä¹ä¸ºç©ºï¼Œæˆ–ä»…æœ‰â€œé™„ä»¶â€äºŒå­—ä½†æ— å…·ä½“è¯´æ˜ã€‚
        4. çº¯ç²¹çš„å•†ä¸šå¹¿å‘Šã€‚
        
        ğŸŸ¢ åˆ¤å®šä¸º YES (æœ‰ä»·å€¼) çš„æƒ…å†µï¼š
        1. åŒ…å«å…·ä½“çš„æ´»åŠ¨æ—¶é—´ã€åœ°ç‚¹ã€å‚ä¸äººå‘˜åå•ã€‚
        2. åŒ…å«ç§‘ç ”é¡¹ç›®ç”³æŠ¥ã€æˆªæ­¢æ—¥æœŸã€æ‹›æ ‡å‚æ•°ã€‚
        3. åŒ…å«å…·ä½“çš„æ–°é—»æŠ¥é“ã€ä¼šè®®çºªè¦ã€‚
        
        è¯·ä»…å›ç­” YES æˆ– NOã€‚
        """
        filter_len = config.AI_CONFIG.get("FILTER_CONTEXT_LEN", 2500)
        is_valuable = self._call_ai("hunter", filter_prompt, full_context[:filter_len])

        if is_valuable and is_valuable.strip().upper().startswith("NO"):
            return False

        return True

    def _generate_summary_content(self, full_context):
        """åŸå­ä»»åŠ¡ï¼šCommander/Strategist æ€»ç»“é€»è¾‘"""
        summary_prompt = """
        ä½ æ˜¯ä¸€ä¸ªä¸“ä¸ºé«˜æ ¡å¸ˆç”ŸæœåŠ¡çš„ã€ä¿¡æ¯æå–åŠ©æ‰‹ã€‘ã€‚è¯·ä»”ç»†é˜…è¯»è¾“å…¥å†…å®¹ï¼Œæå–å…³é”®ä¿¡æ¯ï¼Œä¸è¦è¿‡åº¦æ¦‚æ‹¬ç»†èŠ‚ã€‚

        è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ Markdown æ ¼å¼è¾“å‡ºï¼š

        ğŸ“Œ **æ ‡é¢˜**ï¼š(åŸæ ‡é¢˜ï¼Œå»é™¤éå¿…è¦ä¿®é¥°)

        ğŸ¯ **æ ¸å¿ƒåˆ’é‡ç‚¹**ï¼š
        - (ä¿ç•™å…·ä½“çš„ç ”ç©¶æ–¹å‘ã€æ¯”èµ›èµ›é“ã€æ‹›è˜å²—ä½ç­‰ç»†åˆ†åˆ—è¡¨ï¼Œä¸è¦åªå†™å¤§ç±»ï¼ä¾‹å¦‚ï¼šä¸è¦åªå†™"å†œä¸š"ï¼Œè¦å†™"å†œä¸š(å«æ™ºæ…§å†œä¸šã€é‡‡ååˆ›æ–°ç­‰)")
        - (ä¿ç•™å…·ä½“çš„ç¡¬æ€§è¦æ±‚ï¼Œå¦‚ï¼šæ’åè¦æ±‚ã€ç‰¹å®šä¸“ä¸šã€å¿…é¡»å…·å¤‡çš„è¯ä¹¦)
        - (ä¿ç•™å…·ä½“çš„é‡‘é¢ã€åé¢é™åˆ¶)
        - (å¦‚æœåŒ…å«"æ“ä½œæŒ‡å¼•"ï¼Œè¯·ç®€è¿°å…³é”®æ­¥éª¤ï¼Œå¦‚"éœ€åœ¨ç³»ç»Ÿå¤‡æ³¨æ å¡«å†™XXX")

        ğŸ“ **è”ç³»æ–¹å¼**ï¼š
        - (æå–æ–‡ä¸­çš„è”ç³»äººã€ç”µè¯ã€é‚®ç®±ã€QQç¾¤ã€åŠå…¬åœ°ç‚¹ã€‚å¦‚æœæ²¡æœ‰ï¼Œå†™"æ— ")

        ğŸ“ **é™„ä»¶/é“¾æ¥**ï¼š
        - (æå–æ–‡ä¸­å‡ºç°çš„é‡è¦ç½‘å€ã€æŠ¥åé“¾æ¥ã€é™„ä»¶åç§°)

        â° **æˆªæ­¢æ—¶é—´**ï¼š(ç²¾ç¡®æå–æ—¥æœŸå’Œå…·ä½“æ—¶é—´ç‚¹)
        """
        max_ctx = config.AI_CONFIG.get("MAX_CONTEXT_LEN", 12000)
        summary = self._call_ai("commander", summary_prompt, full_context[:max_ctx])

        if not summary:
            logger.warning("    âš ï¸ Commander å¤±è´¥ï¼Œåˆ‡æ¢ Strategist...")
            summary = self._call_ai("strategist", summary_prompt, full_context[:max_ctx])

        return summary

    # ==========================
    # ğŸš€ ä¸»å…¥å£ (é‡æ„åç»“æ„æç®€)
    # ==========================

    def summarize(self, fetch_result, title=None):
        if not fetch_result: return None

        # 1. å‡†å¤‡ä¸Šä¸‹æ–‡
        safe_title, full_context = self._build_full_context(fetch_result, title)

        # 2. ä»·å€¼è¯„ä¼° (Hunter)
        if not self._check_relevance(safe_title, full_context):
            return "IGNORE"

        # 3. ç”Ÿæˆæ‘˜è¦ (Commander)
        summary = self._generate_summary_content(full_context)

        if not summary:
            return "âš ï¸ AI æ€»ç»“å¤±è´¥ï¼Œè¯·ç›´æ¥æŸ¥çœ‹åŸæ–‡ã€‚"

        return summary